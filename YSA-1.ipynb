{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc50f764-5242-426b-8bbe-87acdc21b669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koray\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koray\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:783: UserWarning: k=15 is greater than n_features=14. All the features will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal veri sınıf dağılımı: Counter({0: 303, 1: 303, 3: 303, 5: 303, 2: 302, 6: 301, 4: 300})\n",
      "SMOTE sonrası sınıf dağılımı: Counter({0: 10000, 1: 10000, 2: 10000, 3: 10000, 4: 10000, 5: 10000, 6: 10000})\n",
      "En iyi RandomForest parametreleri: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "En iyi XGBoost parametreleri: {'estimator__learning_rate': 0.1, 'estimator__max_depth': 5, 'estimator__n_estimators': 200}\n",
      "Mean Absolute Error (MAE): 1.3051942814970425\n",
      "Root Mean Squared Error (RMSE): 2.5406087854154893\n",
      "R-squared (R²): 0.7983700578321485\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Pandas ayarları\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Veri setini yükle\n",
    "df = pd.read_excel(\"C:/Users/koray/PycharmProjects/pythonProject/DATA SETS/yl11_dataset.xlsx\")\n",
    "\n",
    "# Eksik veri kontrolü ve doldurma\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Aykırı değerleri düzeltme fonksiyonları\n",
    "def outlier_thresholds(dataframe, variable, low_quantile=0.05, up_quantile=0.95):\n",
    "    quantile_one = dataframe[variable].quantile(low_quantile)\n",
    "    quantile_three = dataframe[variable].quantile(up_quantile)\n",
    "    interquantile_range = quantile_three - quantile_one\n",
    "    up_limit = quantile_three + 1.5 * interquantile_range\n",
    "    low_limit = quantile_one - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "\n",
    "num_cols = [col for col in df.columns if df[col].dtypes != \"O\"]\n",
    "for col in num_cols:\n",
    "    replace_with_thresholds(df, col)\n",
    "\n",
    "# SMOTE ile gözlem birimini artırma\n",
    "X = df.drop(columns=[\"su\"])\n",
    "y = df[\"su\"]\n",
    "\n",
    "# SMOTE uygulaması: Her sınıfın örnek sayısını 10000 yapıyoruz\n",
    "smote = SMOTE(sampling_strategy={0: 10000, 1: 10000, 2: 10000, 3: 10000, 4: 10000, 5:10000, 6:10000}, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"Orijinal veri sınıf dağılımı:\", Counter(y))\n",
    "print(\"SMOTE sonrası sınıf dağılımı:\", Counter(y_resampled))\n",
    "\n",
    "# Yeni veri seti oluşturma\n",
    "df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), \n",
    "                          pd.DataFrame(y_resampled, columns=[\"su\"])], axis=1)\n",
    "\n",
    "# Özellik mühendisliği\n",
    "df_resampled['klorofil_su_etkileşim'] = df_resampled['klorofil miktarı'] * df_resampled['su']\n",
    "df_resampled['sıcaklık_su_oranı'] = df_resampled['bitki örtü sıcaklığı'] / (df_resampled['su'] + 1)\n",
    "df_resampled[\"Klorofil_x_Sıcaklık\"] = df_resampled[\"klorofil miktarı\"] * df_resampled[\"bitki örtü sıcaklığı\"]\n",
    "df_resampled['log_klorofil'] = np.log(df_resampled['klorofil miktarı'] + 1)\n",
    "df_resampled['sqrt_sıcaklık'] = np.sqrt(df_resampled['bitki örtü sıcaklığı'])\n",
    "df_resampled = pd.get_dummies(df_resampled, columns=[\"su\"], prefix='su', dtype=int)\n",
    "\n",
    "# Bağımsız ve bağımlı değişkenlerin ayrılması\n",
    "X = df_resampled.drop(columns=['yaprak sap uzunluğu', 'yaprak ağırlığı'])\n",
    "y = df_resampled[['yaprak sap uzunluğu', 'yaprak ağırlığı']]\n",
    "\n",
    "# Verinin ölçeklendirilmesi\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Eğitim ve test verisinin oluşturulması\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# ================================\n",
    "# Özellik Seçimi (SelectKBest)\n",
    "# ================================\n",
    "# f_regression tek hedef için çalıştığından, ilk hedef sütununu kullanıyoruz (yaprak sap uzunluğu)\n",
    "selector = SelectKBest(score_func=f_regression, k=15)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train[:, 0])\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# ================================\n",
    "# PCA ile Boyut Azaltma\n",
    "# ================================\n",
    "pca = PCA(n_components=0.95)  # %95 varyansı koru\n",
    "X_train_pca = pca.fit_transform(X_train_selected)\n",
    "X_test_pca = pca.transform(X_test_selected)\n",
    "\n",
    "# ================================\n",
    "# Farklı Modeller ve Hiperparametre Optimizasyonu\n",
    "# ================================\n",
    "\n",
    "# 1. RandomForestRegressor (multi-output desteği vardır)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_pca, y_train)\n",
    "print(\"En iyi RandomForest parametreleri:\", rf_grid.best_params_)\n",
    "\n",
    "# 2. XGBoost: MultiOutputRegressor ile sarmalayarak multi-output desteği sağlıyoruz\n",
    "xgb_model = MultiOutputRegressor(XGBRegressor(random_state=42))\n",
    "xgb_params = {\n",
    "    'estimator__n_estimators': [100, 200],\n",
    "    'estimator__learning_rate': [0.01, 0.1],\n",
    "    'estimator__max_depth': [3, 5]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "xgb_grid.fit(X_train_pca, y_train)\n",
    "print(\"En iyi XGBoost parametreleri:\", xgb_grid.best_params_)\n",
    "\n",
    "# ================================\n",
    "# En İyi Modelin Seçilmesi ve Değerlendirilmesi\n",
    "# ================================\n",
    "# Burada örneğin XGBoost modelini seçiyoruz\n",
    "best_model = xgb_grid.best_estimator_\n",
    "\n",
    "# Test seti üzerinde tahmin yapma\n",
    "y_pred_scaled = best_model.predict(X_test_pca)\n",
    "\n",
    "# Tahminleri ters ölçeklendirme\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Performans metriklerinin hesaplanması\n",
    "mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred))\n",
    "r2 = r2_score(y_test_actual, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R²): {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
